<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>TL;DR</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>



<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>TL;DR</h2>

<p>First, pick an outlet location and download some data.</p>

<pre><code class="r"># Uncomment to install!
# install.packages(&quot;nhdplusTools&quot;)

library(nhdplusTools)
library(sf)

start_point &lt;- st_sfc(st_point(c(-89.362239, 43.090266)), crs = 4269)
start_comid &lt;- discover_nhdplus_id(start_point)

flowline &lt;- navigate_nldi(list(featureSource = &quot;comid&quot;, 
                               featureID = start_comid), 
                          mode = &quot;upstreamTributaries&quot;, 
                          data_source = &quot;&quot;)

subset_file &lt;- tempfile(fileext = &quot;.gpkg&quot;)
subset &lt;- subset_nhdplus(comids = flowline$nhdplus_comid,
                         output_file = subset_file,
                         nhdplus_data = &quot;download&quot;, 
                         return_data = TRUE)

flowline &lt;- subset$NHDFlowline_Network
catchment &lt;- subset$CatchmentSP
waterbody &lt;- subset$NHDWaterbody

## Or:

flowline &lt;- sf::read_sf(subset_file, &quot;NHDFlowline_Network&quot;)
catchment &lt;- sf::read_sf(subset_file, &quot;CatchmentSP&quot;)
waterbody &lt;- sf::read_sf(subset_file, &quot;NHDWaterbody&quot;)

plot(sf::st_geometry(flowline), col = &quot;blue&quot;)
plot(start_point, cex = 1.5, lwd = 2, col = &quot;red&quot;, add = TRUE)
plot(sf::st_geometry(catchment), add = TRUE)
plot(sf::st_geometry(waterbody), col = rgb(0, 0, 1, alpha = 0.5), add = TRUE)
</code></pre>

<p>Read on to see how NHDPlusTools will help you index data to the network you just retrieved and refactor (split, collapse, and aggregate) the catchments into a different set of catchments. Please consider registering <a href="https://github.com/dblodgett-usgs/nhdplusTools/issues">issues and feature suggestions on github</a>.</p>

<h2>Introduction</h2>

<p>The <code>nhdplusTools</code> package is intended to provide a reusable set of tools to
subset, relate data to, and refactor (collapse, split, and aggregate) NHDPlus data. 
It implements a data model consistent with both the <a href="https://www.epa.gov/waterdata/nhdplus-national-hydrography-dataset-plus">NHDPlus</a>
and <a href="http://opengeospatial.github.io/HY_Features/">HY_Features</a>. The package
aims to provide a set of tools with minimal dependencies that can be used
to build workflows using NHDPlus data.</p>

<p>The package has three types of functionality:</p>

<ol>
<li><a href="#discovery_subsetting">Discovery and Subsetting</a></li>
<li><a href="#indexing">Indexing or Referencing</a></li>
<li><a href="#refactoring">Generalization and Refactoring</a></li>
</ol>

<p>This introduction gives an overview of the basic package setup and an brief demonstration of the three types of functionality. Detailed documentation of all the package functions can be found at the <a href="https://usgs-r.github.io/nhdplusTools/reference/">Referece page</a></p>

<h2>Installation</h2>

<p>The easiest way to install <code>nhdplusTools</code> is with the <code>devtools</code> package like this:</p>

<pre><code class="r"># install.packages(&quot;devtools&quot;)
# devtools::install_github(&quot;usgs-r/nhdplusTools&quot;)
</code></pre>

<p>Then you can load up nhdplusTools:</p>

<pre><code class="r">library(nhdplusTools)
</code></pre>

<h2>Data and Package Basics</h2>

<p>The first thing you are going to need to do is go get some data to work with. <code>nhdplusTools</code> provides the ability to download small subsets of the NHDPlus as described in the <a href="#discovery_subsetting">Discovery and Subsetting</a> section. For large subsets, greater than a few thousand square kilometers, you can download the <a href="https://www.epa.gov/waterdata/nhdplus-national-data">National Seamless database at this web page.</a> You will need <a href="https://www.7-zip.org/">7z</a> or the <a href="https://github.com/jimhester/archive"><code>archive</code> package</a> to extract it. </p>

<p>If you are working with the whole National Seamless database, <code>nhdplusTools</code> has some convenience functions you should be aware of. Once you have it downloaded and extracted, you can tell the nhdplusTools package where it is with the <code>nhdplus_path()</code> function.</p>

<pre><code class="r">nhdplus_path(file.path(temp_dir, &quot;natseamless.gpkg&quot;))

nhdplus_path()
</code></pre>

<p>If you are going to be loading and reloading the flowlines, flowline attributes, or catchments, repeatadly, the <code>stage_national_data()</code> function will speed things up a bit. It creates three staged files that are quicker for R to read at the path you tell it. If you call it and its output files exist, it won&#39;t overwrite and just return the paths to your staged files.</p>

<pre><code class="r">staged_data &lt;- stage_national_data(output_path = tempdir())

str(staged_data)
</code></pre>

<p>As you can see, <code>stage_national_data()</code> assumes you want to stage data in the same folder as the nhdplus_path database and returns a list of .rds files that can be read with readRDS. The flowlines and catchments are <a href="https://r-spatial.github.io/sf/"><code>sf</code></a> <code>data.frame</code>s and attributes is a plain <code>data.frame</code> with the attributes from <code>flowline</code>. Note that this introduction uses a small subset of the national seamless database as shown in the plot. </p>

<pre><code class="r">flowline &lt;- readRDS(staged_data$flowline)
names(flowline)[1:10]

library(sf)
plot(sf::st_geometry(flowline))
</code></pre>

<p><a id="discovery_subsetting"></a></p>

<h3>NHDPlus HiRes</h3>

<p>(6/16/2019) NHDPlus HiRes is an in-development dataset that introduces much more dense flowlines and catchments. In the long run, <code>nhdplusTools</code> will have complete support for NHDPlus HiRes. So far, <code>nhdplusTools</code> will help download and interface NHDPlus HiRes data with existing <code>nhdplusTools</code> functionality. It&#39;s important to note that <code>nhdplusTools</code> was primarily implemented using NHDPlusV2 and any use of HiRes (which is still &ldquo;beta data&rdquo; as of writing this) should be subject to significant scruitiny. Never the less, here&#39;s a short summary of how to work with NHDPlus HiRes.</p>

<p>For the demo below, a small sample of HiRes data that has been loaded into <code>nhdplusTools</code> is used. The first line shows how you can download additional data (just change <code>download_files</code> to <code>TRUE</code>).</p>

<pre><code class="r">download_nhdplushr(nhd_dir = &quot;download_dir&quot;, 
                   hu_list = c(&quot;0101&quot;), # can mix hu02 and hu04 codes.
                   download_files = FALSE) # TRUE will download files.

out_gpkg &lt;- file.path(work_dir, &quot;nhd_hr.gpkg&quot;)
hr_data &lt;- get_nhdplushr(work_dir, 
                         out_gpkg = out_gpkg)
(layers &lt;- st_layers(out_gpkg))
names(hr_data)
unlink(out_gpkg)

hr_data &lt;- get_nhdplushr(work_dir, 
                         out_gpkg = out_gpkg, 
                         layers = NULL)
(layers &lt;- st_layers(out_gpkg))
names(hr_data)
</code></pre>

<p>Other functionality in the package, such as the <code>get_UT/UM/DM/DD</code> functions, subsetting, indexing, etc. also work now or will soon! Stay tuned for a dedicated NHDPlus HiRes vignette and submit issues as you find them! </p>

<h2>Discovery and Subsetting</h2>

<p>One of the primary workflows <code>nhdplusTools</code> is designed to accomplish can be described in three steps:</p>

<ol>
<li>what NHDPlus catchment is at the outlet of a watershed, </li>
<li>figure out what catchments are up or downstream of that catchment, and </li>
<li>create a stand alone subset for that collection of catchments.</li>
</ol>

<p>Say we want to get a subset of the NHDPlus upstream of a given location. We can start with <code>discover_nhdplus_id()</code> First, let&#39;s look at a given point location. Then see where it is relative to our flowlines.</p>

<pre><code class="r">lon &lt;- -89.362239
lat &lt;- 43.090266

start_point &lt;- sf::st_sfc(sf::st_point(c(lon, lat)),
                          crs = 4269)

plot(sf::st_geometry(flowline))
plot(start_point, cex = 1.5, lwd = 2, col = &quot;red&quot;, add = TRUE)
</code></pre>

<p>OK, so we have a point location near a river and we want to figure out what catchment is at its outlet. We can use the <code>discover_nhdplus_id()</code> function which calls out to a web service and returns an NHDPlus catchment identifier, typically called a COMID.</p>

<pre><code class="r">start_comid &lt;- discover_nhdplus_id(start_point)
start_comid
</code></pre>

<p><strong>If you have the whole National Seamless database and want to work at regional to national scales, skip down the the Local Data Subsetting section.</strong></p>

<h3>Web Service Data Subsetting</h3>

<p><code>nhdplusTools</code> supports discovery and data subsetting using web services made available through the <a href="https://owi.usgs.gov/blog/nldi-intro/">Network Linked Data Index</a> (NLDI) and the <a href="https://cida.usgs.gov/nwc/geoserver">National Water Census Geoserver.</a> The code below shows how to use the NLDI functions to build a dataset upstream of our <code>start_comid</code> that we found above.</p>

<p>The NLDI can be queried with any set of watershed outlet locations that it has in its index. We call these &ldquo;featureSources&rdquo;. We can query the NLDI for an identifier of a given feature from any of its &ldquo;featureSources&rdquo; and find out what our navigation options are as shown below.</p>

<pre><code class="r">discover_nldi_sources()$source

nldi_feature &lt;- list(featureSource = &quot;comid&quot;, featureID = start_comid)
discover_nldi_navigation(nldi_feature)
</code></pre>

<p>The <code>discover_nldi_navigation</code> function is a handy way to make sure the featureID is available for the chosen &ldquo;featureSource&rdquo; as well as find valid navigation modes to be used with <code>navigate_nldi</code>. Now that we know the NLDI has our comid, we can use the &ldquo;upstreamTributaries&rdquo; navigation option to get all the flowlines upstream or all the features from any of the &ldquo;featureSources&rdquo; as shown below. </p>

<pre><code class="r">
flowline_nldi &lt;- navigate_nldi(nldi_feature, 
                               mode = &quot;upstreamTributaries&quot;, 
                               data_source = &quot;&quot;)

plot(sf::st_geometry(flowline), lwd = 3, col = &quot;black&quot;)
plot(sf::st_geometry(flowline_nldi), lwd = 1, col = &quot;red&quot;, add = TRUE)
</code></pre>

<p>What is not shown here is that the NLDI only provided geometry and a comid for each of the flowlines. The <code>subset_nhdplus</code> function has a &ldquo;download&rdquo; option that allows us to download four layers and all attributes as shown below. </p>

<pre><code class="r">output_file_download &lt;- file.path(temp_dir, &quot;subset_download.gpkg&quot;)

output_file_download &lt;-subset_nhdplus(comids = flowline_nldi$nhdplus_comid,
                             output_file = output_file_download,
                             nhdplus_data = &quot;download&quot;, return_data = FALSE)

sf::st_layers(output_file_download)

flowline_download &lt;- sf::read_sf(file.path(temp_dir, &quot;subset_download.gpkg&quot;), 
                                 &quot;NHDFlowline_Network&quot;)

plot(sf::st_geometry(dplyr::filter(flowline_download, 
                                   streamorde &gt; 2)), 
     lwd = 7, col = &quot;darkgrey&quot;)
plot(sf::st_geometry(flowline_nldi), 
     lwd = 3, col = &quot;red&quot;, add = TRUE)
</code></pre>

<p>This plot illustrates the kind of thing that&#39;s possible (filtering to specific stream orders) using the attributes that are downloaded.</p>

<p>Notice that the data downloaded above only has four layers where the subset we build below has more. This functionality should be considered beta in nature, but may be useful for some applications so has been included.</p>

<p>Before moving on, one more demonstration of what can be done using the NLDI. Say we knew the USGS gage ID that we want NHDPlus data upstream of. We can use the NLDI to navigate from the gage the same as we did our comid. We can also get back all the nwis sites the NLDI knows about upstream of the one we chose!</p>

<pre><code class="r">nldi_feature &lt;- list(featureSource = &quot;nwissite&quot;, featureID = &quot;USGS-05428500&quot;)

flowline_nldi &lt;- navigate_nldi(nldi_feature, 
                               mode = &quot;upstreamTributaries&quot;, 
                               data_source = &quot;&quot;)

output_file_nwis &lt;- file.path(temp_dir, &quot;subset_download_nwis.gpkg&quot;)

output_file_nwis &lt;-subset_nhdplus(comids = flowline_nldi$nhdplus_comid,
                                  output_file = output_file_nwis,
                                  nhdplus_data = &quot;download&quot;,
                                  return_data = FALSE)

sf::st_layers(output_file_download)

flowline_nwis &lt;- sf::read_sf(output_file_nwis, 
                                 &quot;NHDFlowline_Network&quot;)

upstream_nwis &lt;- navigate_nldi(nldi_feature,
                               mode = &quot;upstreamTributaries&quot;,
                               data_source = &quot;nwissite&quot;)

plot(sf::st_geometry(flowline_nwis), 
     lwd = 3, col = &quot;blue&quot;)
plot(sf::st_geometry(upstream_nwis), 
     cex = 1, lwd = 2, col = &quot;red&quot;, add = TRUE)
</code></pre>

<h3>Local Data Subsetting</h3>

<p>With the starting COMID we found with <code>discover_nhdplus_id</code> above, we can use one of the network navigation functions, <code>get_UM</code>, <code>get_UT</code>, <code>get_DM</code>, or <code>get_DD</code> to retrieve a collection of comids along the upstream mainstaem, upstream with tributaries, downstream mainstem, or downstream with diversions network paths. Here we&#39;ll use upstream with tributaries.</p>

<pre><code class="r">UT_comids &lt;- get_UT(flowline, start_comid)
UT_comids
</code></pre>

<p>If you are familiar with the NHDPlus, you will recognize that now that we have this list of COMIDs, we could go off and do all sorts of things with the various flowline attributes. For now, let&#39;s just use the COMID list to filter our <code>fline</code> <code>sf</code> <code>data.frame</code> and plot it with our other layers.</p>

<pre><code class="r">plot(sf::st_geometry(flowline))
plot(start_point, cex = 1.5, lwd = 2, col = &quot;red&quot;, add = TRUE)
plot(sf::st_geometry(dplyr::filter(flowline, COMID %in% UT_comids)),
     add=TRUE, col = &quot;red&quot;, lwd = 2)
</code></pre>

<p>Say you want to save the network subset for later use in R or in some other GIS. The subset_nhdplus() function is your friend. If you have the whole national seamless database downloaded, you can pull out large subsets of it like shown below. If you don&#39;t have the whole national seamless, look at the second example in this section.</p>

<pre><code class="r">output_file &lt;- file.path(temp_dir, &quot;subset.gpkg&quot;)

output_file &lt;-subset_nhdplus(comids = UT_comids,
                             output_file = output_file,
                             nhdplus_data = nhdplus_path(), 
                             return_data = FALSE)

sf::st_layers(output_file)
</code></pre>

<p>Now we have an output geopackage that can be used later. It contains the network subset of catchments and flowlines as well as a spatial subset of other laters as shown in the status output above. To complete the demonstration, here are a couple more layers plotted up.</p>

<pre><code class="r">catchment &lt;- sf::read_sf(output_file, &quot;CatchmentSP&quot;)
waterbody &lt;- sf::read_sf(output_file, &quot;NHDWaterbody&quot;)

plot(sf::st_geometry(flowline))
plot(start_point, cex = 1.5, lwd = 2, col = &quot;red&quot;, add = TRUE)
plot(sf::st_geometry(dplyr::filter(flowline, COMID %in% UT_comids)),
     add=TRUE, col = &quot;red&quot;, lwd = 2)
plot(sf::st_geometry(catchment), add = TRUE)
plot(sf::st_geometry(waterbody), col = rgb(0, 0, 1, alpha = 0.5), add = TRUE)
</code></pre>

<p><a id="indexing"></a></p>

<h2>Indexing</h2>

<p>Expect more in this space as <code>nhdplustTools</code> progresses. Right now, one indexing method has been implemented. Using the data above, we can use the <code>get_flowline_index()</code> function to get the comid, reachcode, and measure of our starting point like this.</p>

<pre><code class="r">get_flowline_index(flowline, start_point)
</code></pre>

<p><code>get_flowline_index()</code> will work with a list of points too. For demonstration purposes, we can use the gages in our subset from above.</p>

<pre><code class="r">gage &lt;- sf::read_sf(output_file, &quot;Gage&quot;)

get_flowline_index(flowline, sf::st_geometry(gage), precision = 10)
</code></pre>

<p>For more info about <code>get_flowline_index()</code> see the article <code>vignette(&quot;point_indexing&quot;)</code> about it or the reference page that describes it.</p>

<p><a id="refactoring"></a></p>

<h2>Refactoring</h2>

<p>The NHDPlus tools package has been developed in support of an experimental NHDPlus refactoring workflow to normalize the size of catchments and resolve particular network locations. If this work is of interest, it can be found in the network_refactor branch of this repository.</p>

</body>

</html>
